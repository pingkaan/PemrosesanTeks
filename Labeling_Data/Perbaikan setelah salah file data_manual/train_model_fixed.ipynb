{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e0fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6c564a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training data: data_manual.csv\n",
      "✓ New data: data_self_training.csv\n",
      "✓ Label column: label_manual\n",
      "✓ Text column: preprocessed_text\n",
      "✓ Models to train: ['Linear Regression', 'LLM']\n",
      "✓ Model output: sentiment_model.pkl\n",
      "✓ Labeled output: data_labeled_result.csv\n"
     ]
    }
   ],
   "source": [
    "# Konfigurasi\n",
    "TRAINING_DATA = \"data_manual.csv\"           # File data training (harus punya label)\n",
    "NEW_DATA = \"data_self_training.csv\"         # File data baru yang akan dilabeli\n",
    "LABEL_COLUMN = \"label_manual\"               # Nama kolom label di training data\n",
    "TEXT_COLUMN = \"preprocessed_text\"           # Nama kolom text/review\n",
    "\n",
    "# Pilih model yang ingin digunakan (hanya Linear Regression dan LLM)\n",
    "MODELS_TO_TRAIN = {\n",
    "    'Linear Regression': True,   # Logistic Regression (linear model)\n",
    "    'LLM': True                  # Large Language Model\n",
    "}\n",
    "\n",
    "MODEL_OUTPUT = \"sentiment_model.pkl\"\n",
    "LABELED_OUTPUT = \"data_labeled_result.csv\"\n",
    "\n",
    "print(f\"✓ Training data: {TRAINING_DATA}\")\n",
    "print(f\"✓ New data: {NEW_DATA}\")\n",
    "print(f\"✓ Label column: {LABEL_COLUMN}\")\n",
    "print(f\"✓ Text column: {TEXT_COLUMN}\")\n",
    "print(f\"✓ Models to train: {[k for k,v in MODELS_TO_TRAIN.items() if v]}\")\n",
    "print(f\"✓ Model output: {MODEL_OUTPUT}\")\n",
    "print(f\"✓ Labeled output: {LABELED_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3c28b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training dataset loaded: (250, 4)\n",
      "✓ Text column: 'preprocessed_text'\n"
     ]
    }
   ],
   "source": [
    "# Load Data Training\n",
    "try:\n",
    "    data_train = pd.read_csv(TRAINING_DATA)\n",
    "    print(f\"✓ Training dataset loaded: {data_train.shape}\")\n",
    "    \n",
    "    # Check label column exists\n",
    "    if LABEL_COLUMN not in data_train.columns:\n",
    "        raise ValueError(f\"Kolom '{LABEL_COLUMN}' tidak ditemukan di {TRAINING_DATA}\")\n",
    "    \n",
    "    # Auto-detect text column if TEXT_COLUMN not found\n",
    "    if TEXT_COLUMN not in data_train.columns:\n",
    "        text_candidates = data_train.select_dtypes(include=['object']).columns.tolist()\n",
    "        if text_candidates:\n",
    "            TEXT_COLUMN = text_candidates[0]\n",
    "            print(f\"⚠ Kolom text otomatis terdeteksi: '{TEXT_COLUMN}'\")\n",
    "        else:\n",
    "            raise ValueError(\"Tidak dapat menemukan kolom text!\")\n",
    "    \n",
    "    print(f\"✓ Text column: '{TEXT_COLUMN}'\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ File '{TRAINING_DATA}' tidak ditemukan!\")\n",
    "    print(\"Pastikan file berada di folder yang sama dengan notebook ini.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cbf4176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Label distribution:\n",
      "   - negatif: 100\n",
      "   - positif: 100\n",
      "   - netral: 50\n",
      "✓ X_train_full shape: (250,)\n",
      "✓ y_train_full shape: (250,)\n",
      "\n",
      "✓ Data split:\n",
      "   - Training: 200 samples\n",
      "   - Testing: 50 samples\n"
     ]
    }
   ],
   "source": [
    "# Preparing Data Training\n",
    "\n",
    "# Konversi label text ke angka\n",
    "label_mapping = {\n",
    "    'negatif': 0, 'negative': 0, 'neg': 0,\n",
    "    'netral': 1, 'neutral': 1, 'neu': 1,\n",
    "    'positif': 2, 'positive': 2, 'pos': 2\n",
    "}\n",
    "\n",
    "data_train[LABEL_COLUMN] = data_train[LABEL_COLUMN].astype(str).str.lower().str.strip()\n",
    "data_train['label_encoded'] = data_train[LABEL_COLUMN].map(label_mapping)\n",
    "\n",
    "# Hapus baris dengan label tidak valid\n",
    "invalid_mask = data_train['label_encoded'].isna()\n",
    "if invalid_mask.any():\n",
    "    invalid_labels = data_train[invalid_mask][LABEL_COLUMN].unique()\n",
    "    print(f\"⚠ WARNING: Label tidak valid ditemukan: {invalid_labels}\")\n",
    "    data_train = data_train[~invalid_mask]\n",
    "    print(f\"✓ Baris dengan label invalid dihapus. Shape baru: {data_train.shape}\")\n",
    "\n",
    "data_train['label_encoded'] = data_train['label_encoded'].astype(int)\n",
    "\n",
    "print(f\"✓ Label distribution:\")\n",
    "label_counts = data_train[LABEL_COLUMN].value_counts()\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"   - {label}: {count}\")\n",
    "\n",
    "# Prepare features and labels\n",
    "X_train_full = data_train[TEXT_COLUMN].astype(str).values\n",
    "y_train_full = data_train['label_encoded'].values\n",
    "\n",
    "print(f\"✓ X_train_full shape: {X_train_full.shape}\")\n",
    "print(f\"✓ y_train_full shape: {y_train_full.shape}\")\n",
    "\n",
    "# Split data untuk evaluasi\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_full, y_train_full, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y_train_full\n",
    ")\n",
    "print(f\"\\n✓ Data split:\")\n",
    "print(f\"   - Training: {len(X_train)} samples\")\n",
    "print(f\"   - Testing: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40223e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Linear Regression (Logistic Regression) Model...\n",
      "✓ Linear Regression model trained successfully\n",
      "✓ Cross-validation scores: [0.7   0.625 0.65  0.75  0.6  ]\n",
      "✓ Mean CV accuracy: 0.6650 (+/- 0.0539)\n",
      "\n",
      "✓ Test set accuracy: 0.7800 (78.00%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.79      0.95      0.86        20\n",
      "      Netral       1.00      0.10      0.18        10\n",
      "     Positif       0.76      0.95      0.84        20\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.85      0.67      0.63        50\n",
      "weighted avg       0.82      0.78      0.72        50\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  1]\n",
      " [ 4  1  5]\n",
      " [ 1  0 19]]\n",
      "(Baris = True Label, Kolom = Predicted Label)\n"
     ]
    }
   ],
   "source": [
    "# Training Model Linear Regression\n",
    "def create_linear_model():\n",
    "    \"\"\"Create Logistic Regression model pipeline\"\"\"\n",
    "    tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2))\n",
    "    clf = LogisticRegression(solver='liblinear', max_iter=200, random_state=42)\n",
    "    return make_pipeline(tfidf, clf)\n",
    "\n",
    "print(\"Training Linear Regression (Logistic Regression) Model...\")\n",
    "linear_model = create_linear_model()\n",
    "linear_model.fit(X_train, y_train)\n",
    "print(\"✓ Linear Regression model trained successfully\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(linear_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"✓ Cross-validation scores: {cv_scores}\")\n",
    "print(f\"✓ Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_linear = linear_model.predict(X_test)\n",
    "acc_linear = accuracy_score(y_test, y_pred_linear)\n",
    "\n",
    "print(f\"\\n✓ Test set accuracy: {acc_linear:.4f} ({acc_linear*100:.2f}%)\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_linear, \n",
    "                            target_names=['Negatif', 'Netral', 'Positif'],\n",
    "                            zero_division=0))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm_linear = confusion_matrix(y_test, y_pred_linear)\n",
    "print(cm_linear)\n",
    "print(\"(Baris = True Label, Kolom = Predicted Label)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e966d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Transformers library available\n",
      "\n",
      "Testing LLM on sample data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 10/10\n",
      "\n",
      "✓ LLM predictions made for 10 samples\n",
      "\n",
      "Evaluating LLM on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 50/50\n",
      "✓ LLM test set accuracy: 0.4400 (44.00%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negatif       0.44      0.95      0.60        20\n",
      "      Netral       0.00      0.00      0.00        10\n",
      "     Positif       0.43      0.15      0.22        20\n",
      "\n",
      "    accuracy                           0.44        50\n",
      "   macro avg       0.29      0.37      0.28        50\n",
      "weighted avg       0.35      0.44      0.33        50\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0  1]\n",
      " [ 7  0  3]\n",
      " [17  0  3]]\n",
      "(Baris = True Label, Kolom = Predicted Label)\n"
     ]
    }
   ],
   "source": [
    "# Training Model LLM\n",
    "def create_llm_model():\n",
    "    \"\"\"Create LLM-based sentiment analyzer\"\"\"\n",
    "    try:\n",
    "        # Try to use transformers\n",
    "        from transformers import pipeline\n",
    "        print(\"✓ Transformers library available\")\n",
    "        \n",
    "        def llm_predict(texts, batch_size=32):\n",
    "            \"\"\"Predict using pretrained LLM\"\"\"\n",
    "            # Use a pretrained sentiment analysis model\n",
    "            sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "            \n",
    "            predictions = []\n",
    "            total = len(texts)\n",
    "            \n",
    "            for i in range(0, total, batch_size):\n",
    "                batch_texts = list(texts[i:i+batch_size])\n",
    "                results = sentiment_pipeline(batch_texts)\n",
    "                \n",
    "                for result in results:\n",
    "                    label = result['label'].upper()\n",
    "                    score = result['score']\n",
    "                    \n",
    "                    # Map LLM output to our labels (0, 1, 2)\n",
    "                    if 'NEG' in label or 'BAD' in label:\n",
    "                        predictions.append(0)  # Negatif\n",
    "                    elif 'NEU' in label or 'NEUTRAL' in label:\n",
    "                        predictions.append(1)  # Netral\n",
    "                    else:\n",
    "                        predictions.append(2)  # Positif\n",
    "                \n",
    "                # Show progress\n",
    "                if (i + batch_size) % 100 == 0 or i + batch_size >= total:\n",
    "                    print(f\"  Progress: {min(i+batch_size, total)}/{total}\")\n",
    "            \n",
    "            return np.array(predictions)\n",
    "        \n",
    "        return llm_predict\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"⚠ Transformers tidak tersedia, menggunakan fallback model...\")\n",
    "        \n",
    "        # Fallback: Simple rule-based LLM simulation\n",
    "        def fallback_llm_predict(texts):\n",
    "            \"\"\"Fallback simple LLM simulation\"\"\"\n",
    "            predictions = []\n",
    "            \n",
    "            # Simple keyword-based sentiment analysis\n",
    "            neg_keywords = ['buruk', 'jelek', 'gagal', 'error', 'masalah', 'susah', 'sulit']\n",
    "            pos_keywords = ['bagus', 'baik', 'mantap', 'keren', 'suka', 'puas', 'rekomendasi']\n",
    "            neu_keywords = ['biasa', 'standar', 'lumayan', 'cukup', 'rata-rata']\n",
    "            \n",
    "            for text in texts:\n",
    "                text_lower = text.lower()\n",
    "                \n",
    "                neg_count = sum(1 for word in neg_keywords if word in text_lower)\n",
    "                pos_count = sum(1 for word in pos_keywords if word in text_lower)\n",
    "                neu_count = sum(1 for word in neu_keywords if word in text_lower)\n",
    "                \n",
    "                if neg_count > pos_count and neg_count > neu_count:\n",
    "                    predictions.append(0)  # Negatif\n",
    "                elif pos_count > neg_count and pos_count > neu_count:\n",
    "                    predictions.append(2)  # Positif\n",
    "                elif neu_count > 0:\n",
    "                    predictions.append(1)  # Netral\n",
    "                else:\n",
    "                    # Default to neutral if no keywords found\n",
    "                    predictions.append(1)\n",
    "            \n",
    "            return np.array(predictions)\n",
    "        \n",
    "        return fallback_llm_predict\n",
    "\n",
    "# Create LLM predictor\n",
    "llm_predictor = create_llm_model()\n",
    "\n",
    "# Test LLM on sample data\n",
    "print(\"\\nTesting LLM on sample data...\")\n",
    "sample_texts = X_test[:10]  # Test on 10 samples\n",
    "sample_preds = llm_predictor(sample_texts)\n",
    "print(f\"\\n✓ LLM predictions made for {len(sample_preds)} samples\")\n",
    "\n",
    "# If we have labels for test set, evaluate LLM\n",
    "if len(y_test) > 0:\n",
    "    print(\"\\nEvaluating LLM on test set...\")\n",
    "    try:\n",
    "        # Predict on entire test set\n",
    "        y_pred_llm = llm_predictor(X_test)\n",
    "        acc_llm = accuracy_score(y_test, y_pred_llm)\n",
    "        \n",
    "        print(f\"✓ LLM test set accuracy: {acc_llm:.4f} ({acc_llm*100:.2f}%)\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred_llm, \n",
    "                                    target_names=['Negatif', 'Netral', 'Positif'],\n",
    "                                    zero_division=0))\n",
    "        \n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        cm_llm = confusion_matrix(y_test, y_pred_llm)\n",
    "        print(cm_llm)\n",
    "        print(\"(Baris = True Label, Kolom = Predicted Label)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Error evaluating LLM: {str(e)}\")\n",
    "        acc_llm = 0\n",
    "else:\n",
    "    print(\"⚠ No labels available for LLM evaluation\")\n",
    "    acc_llm = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74821080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL                     | TEST ACCURACY   | STATUS    \n",
      "----------------------------------------------------------------------\n",
      "Linear Regression         | 0.7800 (78.00%) | ✅\n",
      "LLM                       | 0.4400 (44.00%) |  \n",
      "\n",
      "✓ Best model: Linear Regression\n",
      "✓ Reason: Higher accuracy (0.7800 vs 0.4400)\n",
      "✓ Final accuracy: 0.7800 (78.00%)\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison\n",
    "print(f\"{'MODEL':25s} | {'TEST ACCURACY':15s} | {'STATUS':10s}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "print(f\"{'Linear Regression':25s} | {acc_linear:.4f} ({acc_linear*100:.2f}%) | {'✅' if acc_linear > acc_llm else ' '}\")\n",
    "print(f\"{'LLM':25s} | {acc_llm:.4f} ({acc_llm*100:.2f}%) | {'✅' if acc_llm > acc_linear else ' '}\")\n",
    "\n",
    "# Select best model\n",
    "if acc_linear >= acc_llm:\n",
    "    best_model = linear_model\n",
    "    best_name = \"Linear Regression\"\n",
    "    best_acc = acc_linear\n",
    "    print(f\"\\n✓ Best model: Linear Regression\")\n",
    "    print(f\"✓ Reason: Higher accuracy ({acc_linear:.4f} vs {acc_llm:.4f})\")\n",
    "else:\n",
    "    best_model = llm_predictor\n",
    "    best_name = \"LLM\"\n",
    "    best_acc = acc_llm\n",
    "    print(f\"\\n✓ Best model: LLM\")\n",
    "    print(f\"✓ Reason: Higher accuracy ({acc_llm:.4f} vs {acc_linear:.4f})\")\n",
    "\n",
    "print(f\"✓ Final accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8ce358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Linear Regression retrained on full dataset\n",
      "✓ Final model: Linear Regression\n",
      "✓ Training samples: 250\n"
     ]
    }
   ],
   "source": [
    "# Retrain Best Model\n",
    "if best_name == \"Linear Regression\":\n",
    "    # Retrain linear regression on full dataset\n",
    "    final_model = create_linear_model()\n",
    "    final_model.fit(X_train_full, y_train_full)\n",
    "    print(\"✓ Linear Regression retrained on full dataset\")\n",
    "    \n",
    "    # Save the model type for later use\n",
    "    model_type = \"linear\"\n",
    "    \n",
    "else:  # LLM\n",
    "    # LLM doesn't need retraining as it's pretrained\n",
    "    final_model = best_model\n",
    "    print(\"✓ LLM is pretrained, no retraining needed\")\n",
    "    \n",
    "    # Save the model type for later use\n",
    "    model_type = \"llm\"\n",
    "\n",
    "print(f\"✓ Final model: {best_name}\")\n",
    "print(f\"✓ Training samples: {len(X_train_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad6d21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model saved to: sentiment_model.pkl\n",
      "✓ Model name: Linear Regression\n",
      "✓ Model type: linear\n",
      "✓ Accuracy: 0.7800 (78.00%)\n",
      "✓ Training samples: 250\n",
      "✓ Label distribution:\n",
      "   - Negatif: 100\n",
      "   - Netral: 50\n",
      "   - Positif: 100\n"
     ]
    }
   ],
   "source": [
    "# Menyimpan Model\n",
    "\n",
    "# Prepare model data for saving\n",
    "model_data = {\n",
    "    'model': final_model,\n",
    "    'model_name': best_name,\n",
    "    'model_type': model_type,\n",
    "    'accuracy': best_acc,\n",
    "    'label_mapping': {0: 'negatif', 1: 'netral', 2: 'positif'},\n",
    "    'label_mapping_reverse': {'negatif': 0, 'netral': 1, 'positif': 2},\n",
    "    'training_samples': len(X_train_full),\n",
    "    'label_distribution': {\n",
    "        'negatif': sum(y_train_full == 0),\n",
    "        'netral': sum(y_train_full == 1),\n",
    "        'positif': sum(y_train_full == 2)\n",
    "    },\n",
    "    'text_column': TEXT_COLUMN,\n",
    "    'vectorizer_config': {\n",
    "        'max_features': 2000,\n",
    "        'ngram_range': (1, 2)\n",
    "    } if model_type == \"linear\" else None\n",
    "}\n",
    "\n",
    "with open(MODEL_OUTPUT, 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(f\"✓ Model saved to: {MODEL_OUTPUT}\")\n",
    "print(f\"✓ Model name: {best_name}\")\n",
    "print(f\"✓ Model type: {model_type}\")\n",
    "print(f\"✓ Accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "print(f\"✓ Training samples: {len(X_train_full)}\")\n",
    "print(f\"✓ Label distribution:\")\n",
    "print(f\"   - Negatif: {model_data['label_distribution']['negatif']}\")\n",
    "print(f\"   - Netral: {model_data['label_distribution']['netral']}\")\n",
    "print(f\"   - Positif: {model_data['label_distribution']['positif']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3501de91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New dataset loaded: (750, 3)\n",
      "✓ X_new shape: (750,)\n"
     ]
    }
   ],
   "source": [
    "# Load Data Baru untuk Prediksi\n",
    "try:\n",
    "    data_new = pd.read_csv(NEW_DATA)\n",
    "    print(f\"✓ New dataset loaded: {data_new.shape}\")\n",
    "    \n",
    "    # Use the same text column as training\n",
    "    if TEXT_COLUMN not in data_new.columns:\n",
    "        text_candidates = data_new.select_dtypes(include=['object']).columns.tolist()\n",
    "        if text_candidates:\n",
    "            text_col = text_candidates[0]\n",
    "            print(f\"⚠ Text column auto-detected: '{text_col}'\")\n",
    "        else:\n",
    "            raise ValueError(\"Tidak dapat menemukan kolom text di data baru!\")\n",
    "    else:\n",
    "        text_col = TEXT_COLUMN\n",
    "    \n",
    "    X_new = data_new[text_col].astype(str).values\n",
    "    print(f\"✓ X_new shape: {X_new.shape}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"⚠ File '{NEW_DATA}' tidak ditemukan\")\n",
    "    print(f\"✓ Model sudah tersimpan dan bisa digunakan nanti\")\n",
    "    data_new = None\n",
    "    X_new = None\n",
    "    text_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f244f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Linear Regression predictions made for 750 samples\n"
     ]
    }
   ],
   "source": [
    "# Membuat Prediksi\n",
    "if data_new is not None:\n",
    "    if model_type == \"linear\":\n",
    "        # Use linear model\n",
    "        predictions = final_model.predict(X_new)\n",
    "        probabilities = final_model.predict_proba(X_new)\n",
    "        \n",
    "        # Add predictions to dataframe\n",
    "        label_decode = {0: 'negatif', 1: 'netral', 2: 'positif'}\n",
    "        data_new['predicted_label'] = [label_decode[p] for p in predictions]\n",
    "        data_new['predicted_label_code'] = predictions\n",
    "        data_new['confidence_negatif'] = probabilities[:, 0]\n",
    "        data_new['confidence_netral'] = probabilities[:, 1]\n",
    "        data_new['confidence_positif'] = probabilities[:, 2]\n",
    "        data_new['confidence_max'] = probabilities.max(axis=1)\n",
    "        \n",
    "        print(f\"✓ Linear Regression predictions made for {len(predictions)} samples\")\n",
    "        \n",
    "    else:  # LLM\n",
    "        # Use LLM\n",
    "        predictions = final_model(X_new)\n",
    "        \n",
    "        # For LLM, we don't have probabilities, so create dummy ones\n",
    "        data_new['predicted_label'] = [model_data['label_mapping'][p] for p in predictions]\n",
    "        data_new['predicted_label_code'] = predictions\n",
    "        \n",
    "        # Create confidence scores (LLM doesn't provide probabilities)\n",
    "        # We'll use a default confidence of 0.8 for all predictions\n",
    "        data_new['confidence_negatif'] = 0.0\n",
    "        data_new['confidence_netral'] = 0.0\n",
    "        data_new['confidence_positif'] = 0.0\n",
    "        data_new['confidence_max'] = 0.8  # Default confidence for LLM\n",
    "        \n",
    "        # Set confidence based on predicted label\n",
    "        for i, pred in enumerate(predictions):\n",
    "            if pred == 0:\n",
    "                data_new.loc[i, 'confidence_negatif'] = 0.8\n",
    "            elif pred == 1:\n",
    "                data_new.loc[i, 'confidence_netral'] = 0.8\n",
    "            else:\n",
    "                data_new.loc[i, 'confidence_positif'] = 0.8\n",
    "        \n",
    "        print(f\"✓ LLM predictions made for {len(predictions)} samples\")\n",
    "        print(\"⚠ Note: LLM predictions use default confidence scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c47517ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Predictions saved to: data_labeled_result.csv\n"
     ]
    }
   ],
   "source": [
    "# Menyimpan Hasil Prediksi\n",
    "if data_new is not None:\n",
    "    data_new.to_csv(LABELED_OUTPUT, index=False)\n",
    "    print(f\"✓ Predictions saved to: {LABELED_OUTPUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0256a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL      | COUNT      | PERCENTAGE  \n",
      "----------------------------------------\n",
      "Negatif    |        519 |      69.20%\n",
      "Netral     |          8 |       1.07%\n",
      "Positif    |        223 |      29.73%\n",
      "\n",
      "✓ Average confidence: 0.5314\n",
      "✓ Minimum confidence: 0.3384\n",
      "✓ Maximum confidence: 0.8569\n"
     ]
    }
   ],
   "source": [
    "# Prediction Summary\n",
    "if data_new is not None:\n",
    "    unique, counts = np.unique(predictions, return_counts=True)\n",
    "    label_names = {0: 'Negatif', 1: 'Netral', 2: 'Positif'}\n",
    "    \n",
    "    print(f\"{'LABEL':10s} | {'COUNT':10s} | {'PERCENTAGE':12s}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for label, count in zip(unique, counts):\n",
    "        pct = (count / len(predictions)) * 100\n",
    "        print(f\"{label_names[label]:10s} | {count:10d} | {pct:10.2f}%\")\n",
    "    \n",
    "    if model_type == \"linear\":\n",
    "        print(f\"\\n✓ Average confidence: {data_new['confidence_max'].mean():.4f}\")\n",
    "        print(f\"✓ Minimum confidence: {data_new['confidence_max'].min():.4f}\")\n",
    "        print(f\"✓ Maximum confidence: {data_new['confidence_max'].max():.4f}\")\n",
    "    else:\n",
    "        print(f\"\\n✓ Model type: LLM (using default confidence scores)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd51cb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions:\n",
      "----------------------------------------------------------------------\n",
      "                                               preprocessed_text predicted_label confidence_max\n",
      "eror pace eror pace gimana baik uninstall login eror tolong baik         negatif          55.8%\n",
      "                                                           rekam         negatif          37.8%\n",
      "                                                          akurat         positif          42.6%\n",
      "                             bantu hitung jarak bener bener mula         positif          51.8%\n",
      "                                                          ganggu         negatif          44.2%\n"
     ]
    }
   ],
   "source": [
    "# Sampel Prediksi\n",
    "if data_new is not None:\n",
    "    print(\"First 5 predictions:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    sample_cols = [text_col, 'predicted_label', 'confidence_max']\n",
    "    sample_data = data_new[sample_cols].head(5).copy()\n",
    "    \n",
    "    # Format confidence as percentage\n",
    "    sample_data['confidence_max'] = sample_data['confidence_max'].apply(\n",
    "        lambda x: f\"{x*100:.1f}%\"\n",
    "    )\n",
    "    \n",
    "    print(sample_data.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "010b1fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final Summary\n",
    "# print(\"✓ Training completed successfully!\")\n",
    "# print(f\"✓ Best model: {best_name}\")\n",
    "# print(f\"✓ Model type: {model_type}\")\n",
    "# print(f\"✓ Model accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "# print(f\"✓ Training samples: {len(X_train_full)}\")\n",
    "\n",
    "# if data_new is not None:\n",
    "#     print(f\"✓ New data predicted: {len(predictions)} samples\")\n",
    "#     print(f\"✓ Output files:\")\n",
    "#     print(f\"   - Model: {MODEL_OUTPUT}\")\n",
    "#     print(f\"   - Predictions: {LABELED_OUTPUT}\")\n",
    "# else:\n",
    "#     print(f\"✓ Model saved: {MODEL_OUTPUT}\")\n",
    "#     print(f\"⚠ New data not found - predictions skipped\")\n",
    "\n",
    "# print(\"\\n\" + \"=\" * 70)\n",
    "# print(\"USAGE INSTRUCTIONS\")\n",
    "# print(\"=\" * 70)\n",
    "\n",
    "# print(f\"\"\"\n",
    "# Untuk menggunakan model di lain waktu:\n",
    "\n",
    "# 1. Load model:\n",
    "#    import pickle\n",
    "#    with open('{MODEL_OUTPUT}', 'rb') as f:\n",
    "#        model_data = pickle.load(f)\n",
    "#        model = model_data['model']\n",
    "#        model_type = model_data['model_type']\n",
    "\n",
    "# 2. Predict new text:\n",
    "#    text = [\"contoh teks review\"]\n",
    "   \n",
    "#    if model_type == \"linear\":\n",
    "#        prediction = model.predict(text)\n",
    "#        probability = model.predict_proba(text)\n",
    "#    else:  # LLM\n",
    "#        prediction = model(text)  # LLM is a function\n",
    "       \n",
    "#    # Convert to label\n",
    "#    label_mapping = {{0: 'negatif', 1: 'netral', 2: 'positif'}}\n",
    "#    predicted_label = label_mapping[prediction[0]]\n",
    "# \"\"\")\n",
    "# print(\"✓ SCRIPT COMPLETED SUCCESSFULLY!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
